{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5a6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import Seq\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e94c400",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-thermophilus.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/4021243613.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import Thermophllic proteins datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mthermo_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-thermophilus.fasta'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthermo_fasta_file\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Will close handle cleanly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0midentifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-thermophilus.fasta'"
     ]
    }
   ],
   "source": [
    "#import Thermophllic proteins datasets\n",
    "thermo_dict = {}\n",
    "with open('/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-thermophilus.fasta') as thermo_fasta_file:  # Will close handle cleanly\n",
    "    identifiers = []\n",
    "    sequence = []\n",
    "    for seq_record in SeqIO.parse(thermo_fasta_file, 'fasta'):  # (generator)\n",
    "        identifiers.append(str(seq_record.id))\n",
    "        sequence.append(str(seq_record.seq))\n",
    "        thermo_dict[str(seq_record.id)] = str(seq_record.seq)\n",
    "\n",
    "thermo_list = list(thermo_dict.items())\n",
    "df_thermo = pd.DataFrame(thermo_list)\n",
    "df_thermo.columns = ['protein','sequence']\n",
    "df_thermo['class'] = 'Thermophillic'\n",
    "print(len(df_thermo.index))\n",
    "#sample 1/5 of the thermo data\n",
    "df_thermo = df_thermo.sample(frac=0.20)\n",
    "print(len(df_thermo.index))\n",
    "print('Thermo data has been processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd72130",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Psychrophillic proteins datasets\n",
    "psychro_dict = {}\n",
    "with open('/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-psychrophilus.fasta') as psychro_fasta_file:  # Will close handle cleanly\n",
    "    psychro_identifiers = []\n",
    "    psychro_sequence = []\n",
    "    for seq_record in SeqIO.parse(psychro_fasta_file, 'fasta'):  # (generator)\n",
    "        psychro_identifiers.append(str(seq_record.id))\n",
    "        psychro_sequence.append(str(seq_record.seq))\n",
    "        psychro_dict[str(seq_record.id)] = str(seq_record.seq)\n",
    "\n",
    "psychro_list = list(psychro_dict.items())\n",
    "df_psychro = pd.DataFrame(psychro_list)\n",
    "df_psychro.columns = ['protein','sequence']\n",
    "df_psychro['class'] = 'Psychrophillic'\n",
    "\n",
    "print('Psychro data has been processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50553203",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-mesophilus.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/923637076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import mesophillic proteins datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmeso_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-mesophilus.fasta'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmeso_fasta_file\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Will close handle cleanly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmeso_identifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmeso_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-mesophilus.fasta'"
     ]
    }
   ],
   "source": [
    "#import mesophillic proteins datasets\n",
    "meso_dict = {}\n",
    "with open('/usr/lusers/achazing/thermo_proteins/ThermoDrift/data/uniprot-mesophilus.fasta') as meso_fasta_file:  # Will close handle cleanly\n",
    "    meso_identifiers = []\n",
    "    meso_sequence = []\n",
    "    for seq_record in SeqIO.parse(meso_fasta_file, 'fasta'):  # (generator)\n",
    "        meso_identifiers.append(str(seq_record.id))\n",
    "        meso_sequence.append(str(seq_record.seq))\n",
    "        meso_dict[str(seq_record.id)] = str(seq_record.seq)\n",
    "\n",
    "meso_list = list(meso_dict.items())\n",
    "df_meso = pd.DataFrame(meso_list)\n",
    "df_meso.columns = ['protein','sequence']\n",
    "df_meso['class'] = 'Mesophillic'\n",
    "\n",
    "print('Meso data has been processed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f955150e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_thermo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/1544752448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# concatenate the three dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_thermo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_meso\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_psychro\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_thermo' is not defined"
     ]
    }
   ],
   "source": [
    "# concatenate the three dataframes\n",
    "df_combine = pd.concat([df_thermo,df_meso,df_psychro]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62835e5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_combine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/1434540684.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgood_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbad_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msequence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_combine\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_combine' is not defined"
     ]
    }
   ],
   "source": [
    "#filter out proteins that don't start with methionine and are greater than 75 aas\n",
    "good_list = []\n",
    "bad_list = []\n",
    "sequence_list = df_combine['sequence'].tolist()\n",
    "for seq in sequence_list:\n",
    "    if seq.startswith('M'):\n",
    "        if len(seq) > 75:\n",
    "            good_list.append(seq)\n",
    "        \n",
    "    else:\n",
    "        bad_list.append(seq)\n",
    "boolean_series = df_combine.sequence.isin(good_list)\n",
    "df_filter = df_combine[boolean_series]\n",
    "print(len(df_combine))\n",
    "print(len(df_filter))\n",
    "#df_filter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fea4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to take in a protein sequence and output a one hot encoded version\n",
    "def one_hot_encode_protein(protein_seq):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVUX_?-\" #  the order of the one hot encoded sequences \n",
    "    aa2num= {x:i for i,x in enumerate(amino_acids)} # create a dictionary that maps amino acid to integer\n",
    "    seq1hot = np.eye(len(amino_acids))[np.array([aa2num.get(res) for res in protein_seq])]\n",
    "    return seq1hot\n",
    "\n",
    "#define a function to take in a protein class and output a one hot encoded version\n",
    "def one_hot_encode_class(Class):\n",
    "    classes = ['Thermophillic','Mesophillic','Psychrophillic'] #  the order of the one hot encoded classes \n",
    "    class2num= {x:i for i,x in enumerate(classes)} # create a dictionary that maps class to integer\n",
    "    class1hot = np.eye(len(classes))[np.array([class2num.get(Class)])]\n",
    "    return class1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb66ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a new function to take in a protein sequence and output a one hot encoded version that is cropped and/or padded\n",
    "def one_hot_encode_protein_new(protein_seq):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVUX_?-\"  #  the order of the one hot encoded sequences \n",
    "    aa2num= {x:i for i,x in enumerate(amino_acids)} # create a dictionary that maps amino acid to integer\n",
    "    if len(protein_seq) > 500:   #this argument deals with proetin sequences that are greater than 500 aas\n",
    "        protein_seq = protein_seq[:500]   #crop the protein to include just the first 500 aas\n",
    "        seq1hot = np.eye(len(amino_acids))[np.array([aa2num.get(res) for res in protein_seq])]   #1hotencode the cropped sequence\n",
    "    if len(protein_seq) < 75:    #this argument deals with sequences that are less than 75 residues\n",
    "        print('your sequences contain some less than 75 aas')\n",
    "    \n",
    "    else:  #if len(protein_seq) > 75 and len(protein_seq) < 500:\n",
    "        protein_seq_len = len(protein_seq)   #calculate the length of the sequence\n",
    "        desired_len = 500   #define the desired array length\n",
    "        seq1hot_min = np.eye(len(amino_acids))[np.array([aa2num.get(res) for res in protein_seq])]   #one hot encode the sequence\n",
    "        empty_res = np.zeros([(desired_len-protein_seq_len),len(amino_acids)])    #define an empty array padded with zeros\n",
    "        seq1hot = np.append(seq1hot_min,empty_res,axis=0)  # append the empty array to the end of the sequence array\n",
    "    return seq1hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c46618",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/3417585820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create a list of one hot encoded protein sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhotencode_seq_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamino_acids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filter' is not defined"
     ]
    }
   ],
   "source": [
    "#create a list of one hot encoded protein sequences\n",
    "seq_list = df_filter['sequence'].tolist()\n",
    "hotencode_seq_array = np.empty((1, len(amino_acids)))\n",
    "num = 0\n",
    "for seq in seq_list:\n",
    "    seq_array = one_hot_encode_protein_new(seq)\n",
    "    #print(seq_array.shape)\n",
    "    hotencode_seq_array = np.concatenate([hotencode_seq_array,seq_array])\n",
    "    num=num+1\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c89e194a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_filter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_36437/1178781737.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create a list of one hot encoded  classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhotencode_class_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhotencode_class_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_filter' is not defined"
     ]
    }
   ],
   "source": [
    "#create a list of one hot encoded  classes\n",
    "class_list = df_filter['class'].tolist()\n",
    "hotencode_class_list = []\n",
    "hotencode_class_array = np.empty((1, len(classes)))\n",
    "for c in class_list:\n",
    "    #maybe use .tolist()\n",
    "    hotencode_class_list.append(one_hot_encode_class(c))\n",
    "    c_array = one_hot_encode_class(c)\n",
    "    hotencode_class_array = np.concatenate([hotencode_class_array,c_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed216852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the arrays into tensors and save them for training and testing the CNN model\n",
    "my_x = hotencode_seq_array\n",
    "my_y = hotencode_class_array\n",
    "\n",
    "tensor_x = torch.Tensor(my_x) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(my_y)  # transform to torch tensor\n",
    "\n",
    "torch.save(tensor_x, 'tensor_x.pt') #download tensor to share for training\n",
    "torch.save(tensor_y, 'tensor_y.pt') #download tensor to share for training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
