{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a5a6b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import Bio\n",
    "from Bio import Seq\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6433eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data file paths for running locally/testing\n",
    "thermo_path_local = '../../../data_sets/thermal_proteins/uniprot-thermophilus.fasta'\n",
    "psychro_path_local = '../../../data_sets/thermal_proteins/uniprot-psychrophilus.fasta'\n",
    "meso_path_local = '../../../data_sets/thermal_proteins/uniprot-mesophilus.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecd3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the fasta_to_classified_df function; which inputs fasta seqs and classifies them in a df\n",
    "def fasta_to_classified_df(fasta_path,protein_class='',sample=False):\n",
    "    seq_dict = {}  #define empty dict to store sequence ids and sequences\n",
    "    with open(fasta_path) as fasta_file:  # Will close handle cleanly\n",
    "        identifiers = []   #define empty list \n",
    "        sequence = []\n",
    "        for seq_record in SeqIO.parse(fasta_path, 'fasta'):  # (generator)\n",
    "            identifiers.append(str(seq_record.id))\n",
    "            sequence.append(str(seq_record.seq))\n",
    "            seq_dict[str(seq_record.id)] = str(seq_record.seq)\n",
    "    seq_list = list(seq_dict.items())\n",
    "    df_seqs = pd.DataFrame(seq_list)\n",
    "    df_seqs.columns = ['protein','sequence']\n",
    "    df_seqs['class'] = protein_class\n",
    "    if sample=True:\n",
    "        df_seqs = df_seqs.sample\n",
    "    print(len(df_seqs.index))\n",
    "    return df_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48036375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103591\n",
      "19386\n",
      "23618\n"
     ]
    }
   ],
   "source": [
    "#test the fasta_to_classified_df function\n",
    "df_thermo = fasta_to_classified_df(thermo_path_local,protein_class='Thermophillic',sample=True)\n",
    "df_meso = fasta_to_classified_df(meso_path_local,protein_class='Mesophillic')\n",
    "df_psychro = fasta_to_classified_df(psychro_path_local,protein_class='Psychrophillic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354a37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combine_dfs function; which concatenates the three dataframes\n",
    "def combine_dfs(list_of_dfs):\n",
    "    df_combine = pd.concat(list_of_dfs).reset_index(drop=True)\n",
    "    return df_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfee1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the combine_dfs function\n",
    "list_dfs = [df_thermo,df_meso,df_psychro]\n",
    "df_combine = combine_dfs(list_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01572840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the filter_seqs function\n",
    "def filter_seqs(df_seqs):\n",
    "    good_list = []\n",
    "    bad_list = []\n",
    "    sequence_list = df_seqs['sequence'].tolist()\n",
    "    for seq in sequence_list:\n",
    "        if seq.startswith('M'):\n",
    "            if len(seq) > 75:\n",
    "                good_list.append(seq)\n",
    "\n",
    "        else:\n",
    "            bad_list.append(seq)\n",
    "    boolean_series = df_combine.sequence.isin(good_list)\n",
    "    df_filter = df_combine[boolean_series]\n",
    "    return df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f955150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the filter_seqs function\n",
    "df_filter = filter_seqs(df_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9f136f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lists of filtered sequences and classes\n",
    "seq_list = df_filter['sequence'].tolist()\n",
    "class_list = df_filter['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9219098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the seq1hot function\n",
    "def seq1hot(seq_list):\n",
    "    amino_acids = \"ARNDCQEGHILKMFPSTWYVUX_?-\"  #  the order of the one hot encoded amino acids and other symbols\n",
    "    aa2num= {x:i for i,x in enumerate(amino_acids)} # create a dictionary that maps amino acid to integer\n",
    "    X_data = torch.tensor([])    #define an empty tensor to store one hot encoded proteins seqs\n",
    "    for i,seq in enumerate(seq_list): \n",
    "        if len(seq) > 500:    #crop sequences longer than 500 aas\n",
    "            seq = seq[:500]     \n",
    "        protein1hot = np.eye(len(amino_acids))[np.array([aa2num.get(res) for res in seq])]    #one hot encode protein seq\n",
    "        tensor = torch.tensor(protein1hot)    #create a tensor of one hot encoded proteins sequences \n",
    "        tensor = torch.nn.functional.pad(tensor, (0,0,0,500-len(seq)))   #for sequences less than 500 aas pad the end with zeros\n",
    "        if X_data.size()[0] == 0:    #for the first iteration create an empty tensor\n",
    "            X_data = tensor[None]\n",
    "            print('Just made new tensor X_data')\n",
    "        else:\n",
    "            X_data = torch.cat((X_data,tensor[None]), axis=0)    #for each iteration concatenate the new sequence tensor to existing tensor\n",
    "            if i % 1000 == 0:    #update user on the status of 1hotencoding, which is quite computationally expensive \n",
    "                print(f'Looped through {int(i)} sequences...')\n",
    "    print(X_data.shape)\n",
    "    print(type(X_data))\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b55fd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just made new tensor X_data\n",
      "Looped through 1000 sequences...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_45053/2660910324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#test the seq1hot function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq1hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gb/95qmct013qvgs3x2c2qn2s780000gn/T/ipykernel_45053/2809076795.py\u001b[0m in \u001b[0;36mseq1hot\u001b[0;34m(seq_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Just made new tensor X_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m#for each iteration concatenate the new sequence tensor to existing tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m#update user on the status of 1hotencoding, which is quite computationally expensive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Looped through {int(i)} sequences...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test the seq1hot function\n",
    "X_data = seq1hot(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae7911a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the class1hot function\n",
    "def class1hot(class_list):\n",
    "    classes = ['Thermophillic','Mesophillic','Psychrophillic']   #the order of the one hot encoded classes\n",
    "    class2num= {x:i for i,x in enumerate(classes)}    #  create a dictionary that maps class to integer\n",
    "    y_data = torch.tensor([])   #define empty tensor to store class data\n",
    "    class_temp = [class2num[s] for s in class_list]   #loop through each class in the clast list and map string to dict\n",
    "    y_data = torch.nn.functional.one_hot(torch.tensor(class_temp),3)  #one hot encode the classes as defined by the dict\n",
    "    print(type(y_data))\n",
    "    print(y_data.shape)\n",
    "    return y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d0f0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([133424, 3])\n"
     ]
    }
   ],
   "source": [
    "#test the class1hot function\n",
    "y_data = class1hot(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed216852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the arrays into tensors and save them for training and testing the CNN model\n",
    "  # transform to torch tensor\n",
    "\n",
    "torch.save(X_data, 'test_x.pt') #download tensor to share for training\n",
    "torch.save(y_data, 'test_y.pt') #download tensor to share for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b02accdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X_array = test_x.numpy()\n",
    "y_array = test_y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23a476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae77355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e13e623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert that the length of the sequences are 500 aas\n",
    "assert 500 == X_array.shape[1]\n",
    "\n",
    "# assert that the number of amino acids is 25\n",
    "assert 25 == X_array.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "# Define a class in which the tests will run\n",
    "class TestDataLoader(unittest.TestCase):\n",
    "        \n",
    "    def test_oneshot(self):\n",
    "        self.assertEqual(geomean([1,1]), 1)\n",
    "        \n",
    "    def test_oneshot2(self):\n",
    "        self.assertEqual(geomean([3, 3, 3]), 3)\n",
    "        \n",
    "#test_setup(TestGeomean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dd3ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert that the length of classes is 100\n",
    "assert 100 == y_array.shape[0]\n",
    "\n",
    "#assert that the number of classes is 3 (thermo, meso, psychro)\n",
    "assert 3 == y_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3a9633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab3b4e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thermophillic\n"
     ]
    }
   ],
   "source": [
    "#test to make sure the sequences and classes were one hot encoded properly\n",
    "test1 = seq_list[999]\n",
    "test2 = class_list[999]\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f925a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "hot1_test1 = one_hot_encode_protein(test1)\n",
    "hot1_test2 = one_hot_encode_class(test2)\n",
    "class2num\n",
    "print(hot1_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3a9e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "y_4real: tensor([[1, 0, 0]])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([1, 3])\n",
      "tensor([[1, 0, 0]])\n",
      "tensor([[1., 0., 0.]], dtype=torch.float64)\n",
      "tensor([[1, 0, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_4real = torch.load('tensor_x.pt')[999]\n",
    "y_4real = torch.load('tensor_y.pt')[999][None]\n",
    "print(y_4real.size())\n",
    "print(f'y_4real: {y_4real}')\n",
    "#test_x = [aa2num[s] for s in seq_list[-1]]\n",
    "onehot_x = torch.tensor(one_hot_encode_protein(test1))\n",
    "onehot_y_temp = torch.tensor(one_hot_encode_class(test2))\n",
    "onehot_y = torch.nn.functional.one_hot(torch.tensor([class2num[test2]]),3)\n",
    "print(onehot_y_temp.shape)\n",
    "print(onehot_y.shape)\n",
    "#onehot_x.size()\n",
    "print(y_4real)\n",
    "print(onehot_y_temp)\n",
    "print(onehot_y)\n",
    "\n",
    "torch.equal(y_4real.long(),onehot_y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fea995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_list: 59477\n",
      "class_list: 59477\n",
      "x_data: torch.Size([100, 500, 25])\n"
     ]
    }
   ],
   "source": [
    "print(f'seq_list: {len(seq_list)}')\n",
    "print(f'class_list: {len(seq_list)}')\n",
    "print(f'x_data: {X_data.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30a42ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_x = torch.load('tensor_x.pt')\n",
    "tensor_y = torch.load('tensor_y.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28bd5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59459, 500, 25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00a675d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([59459, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd15f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
